{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igr44zdUIair"
   },
   "source": [
    "# **LAB03:** Implement a Simple Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 21064,
     "status": "ok",
     "timestamp": 1738417089023,
     "user": {
      "displayName": "LUIS ANGEL NIZAMA SARMIENTO",
      "userId": "04326656531487921652"
     },
     "user_tz": 300
    },
    "id": "Yd3mVdA0QbHt",
    "outputId": "a7a5f297-38da-4e47-caea-46faaccf73f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.9)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install transformers \n",
    "\n",
    "!pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlIKWzByIC4n"
   },
   "source": [
    "## **Example 01:** Tutor - Mechatronics Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyRqeyX_XNDK",
    "outputId": "29f1224d-2760-4197-92ea-585370b63497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the agent's context:\n",
      "1. Mechatronics\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "class MechatronicsAgent:\n",
    "    def __init__(self, context=\"Mechatronics\"):\n",
    "        \"\"\"\n",
    "        Initialize the agent with a specific context, such as 'Mechatronics'.\n",
    "        \"\"\"\n",
    "        self.context = context\n",
    "        self.model_name = \"facebook/blenderbot-400M-distill\"\n",
    "        self.tokenizer = BlenderbotTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = BlenderbotForConditionalGeneration.from_pretrained(self.model_name)\n",
    "\n",
    "    def process_input(self, user_input):\n",
    "        \"\"\"\n",
    "        Process user input and generate an appropriate response.\n",
    "        \"\"\"\n",
    "        # Create a context-aware prompt\n",
    "        prompt = (\n",
    "            f\"Context: {self.context}. \"\n",
    "            f\"A student said: \\\"{user_input}\\\". \"\n",
    "            \"Please respond with a clear, helpful action or explanation related to medicine. \"\n",
    "            \"Focus on troubleshooting, explaining concepts, or guiding the student in simple steps.\"\n",
    "        )\n",
    "\n",
    "        # Tokenize the prompt\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "        # Generate the response\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=100,  # Maximum length of the response\n",
    "            num_beams=5,     # Use beam search for more coherent answers\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        # Decode and clean the response\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        return response\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Run the interactive agent loop.\n",
    "        \"\"\"\n",
    "        print(f\"{self.context} agent initialized. Type 'exit' to quit.\\n\")\n",
    "\n",
    "        while True:\n",
    "            user_input = input(\"Student: \").strip()\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"Exiting the agent. Goodbye!\")\n",
    "                break\n",
    "\n",
    "            # Process the student's input\n",
    "            response = self.process_input(user_input)\n",
    "            print(f\"Agent: {response}\")\n",
    "\n",
    "# Initialize and run the agent\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Select the agent's context:\")\n",
    "    print(\"1. Mechatronics\")\n",
    "    context_choice = input(\"Enter the number for the context: \").strip()\n",
    "\n",
    "    if context_choice == \"1\":\n",
    "        context = \"Mechatronics\"\n",
    "    else:\n",
    "        print(\"Invalid choice. Defaulting to 'Mechatronics'.\")\n",
    "        context = \"Mechatronics\"\n",
    "\n",
    "    agent = MechatronicsAgent(context=context)\n",
    "    agent.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTdhki-qqB59"
   },
   "source": [
    "## **Example 02:** Tutor - STEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53816,
     "status": "ok",
     "timestamp": 1737924277430,
     "user": {
      "displayName": "LUCIA GABRIELA SARMIENTO CALDERON",
      "userId": "02362974078023845311"
     },
     "user_tz": 300
    },
    "id": "iruk_KaCSRBA",
    "outputId": "101c3e1d-eee5-4e84-f0c6-a4f0adb2ff0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEM (Science, Technology, Engineering, and Mathematics) Tutor initialized. Type 'exit' to quit.\n",
      "\n",
      "Student: what is math\n",
      "\n",
      "Tutor: Mathematics, often referred to as math, is the study of numbers, quantity, structure, space, and change. It involves logical reasoning and the use of symbols and formulas to solve problems and make predictions. Mathematics is used in a wide range of fields, including science, engineering, economics, and finance, to name a few. It is a fundamental tool for understanding the world around us and for developing new technologies and innovations.\n",
      "\n",
      "Student: what is an algorithm?\n",
      "\n",
      "Tutor: An algorithm is a step-by-step procedure or set of rules designed to solve a specific problem or perform a particular task. Algorithms are used in various fields, including computer science, mathematics, and engineering. In computer science, algorithms are essential for writing computer programs and developing software applications. They provide a systematic way to solve problems and achieve desired outcomes efficiently and accurately. Algorithms can range from simple to complex, depending on the complexity of the task they are designed to address.\n",
      "\n",
      "Student: exit\n",
      "Exiting the tutor. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Conversation history\n",
    "conversation = [{\"role\": \"system\", \"content\": \"You are a STEM tutor.You are fiendly and kind with the user. You are a tutor that loves to make jokes\"}]\n",
    "\n",
    "print(\"STEM (Science, Technology, Engineering, and Mathematics) Tutor initialized. Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    # Student input\n",
    "    user_input = input(\"\\nStudent: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Exiting the tutor. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Add user input to the conversation history\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    try:\n",
    "        # Call the GPT model\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=conversation,\n",
    "            temperature=0.7,\n",
    "            max_tokens=200\n",
    "        )\n",
    "\n",
    "        # Get and display the response\n",
    "        tutor_response = response.choices[0].message.content\n",
    "        print(f\"\\nTutor: {tutor_response}\")\n",
    "\n",
    "        # Add tutor's response to the conversation history\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": tutor_response})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1suOr6CJzp8"
   },
   "source": [
    "## **Ejemplo 03:** Conversation Between Two Avatars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42303,
     "status": "ok",
     "timestamp": 1738205998134,
     "user": {
      "displayName": "LUCIA GABRIELA SARMIENTO CALDERON",
      "userId": "02362974078023845311"
     },
     "user_tz": 300
    },
    "id": "SPkJHvt-JPkl",
    "outputId": "70d9acf9-2c5b-42d7-aef8-80e609b7c7f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Math Genius: Hello! How can I assist you today?\n",
      "\n",
      "Physics Expert: Hello! How can I assist you today?\n",
      "\n",
      "Math Genius: I have a problem that I am trying to solve. Can you help me with it?\n",
      "\n",
      "Physics Expert: Of course! I'd be happy to help. Please go ahead and tell me about the problem you're trying to solve.\n",
      "\n",
      "Math Genius: I'm trying to find the roots of a quadratic equation. Can you guide me through the process?\n",
      "\n",
      "Physics Expert: Sure, I'd be glad to guide you! Quadratic equations are typically in the form ax^2 + bx + c = 0, where a, b, and c are constants. \n",
      "\n",
      "The general method for finding the roots of such an equation is by using the quadratic formula, which is given by:\n",
      "\n",
      "x = [ -b ± sqrt(b^2 - 4ac) ] / 2a\n",
      "\n",
      "Here are the steps:\n",
      "\n",
      "1. Identify the values of a, b, and c in your equation.\n",
      "\n",
      "2. Substitute these values into the quadratic formula.\n",
      "\n",
      "3. Calculate the value inside the square root (b^2 - 4ac), which is known as the discriminant.\n",
      "\n",
      "4. If the discriminant is positive,\n",
      "\n",
      "Math Genius: the equation has two distinct real roots. If the discriminant is zero, the equation has one real root (a repeated root). And if the discriminant is negative, the equation has two complex roots.\n",
      "\n",
      "5. Finally, plug the values of a, b, and c into the quadratic formula and solve for x using the appropriate case based on the value of the discriminant.\n",
      "\n",
      "Let me know the values of a, b, and c in your quadratic equation, and I can help you find the roots.\n",
      "\n",
      "Physics Expert: You're absolutely correct. Depending on the value of the discriminant (b² - 4ac), we can determine the nature of the roots of the quadratic equation. \n",
      "\n",
      "Now go ahead and give me the specific quadratic equation you're working with so we can find its roots.\n",
      "\n",
      "Math Genius: Certainly! Please provide me with the coefficients a, b, and c of your quadratic equation in the form ax^2 + bx + c = 0, and I will help you find the roots.\n",
      "\n",
      "Physics Expert: You're absolutely correct. Depending on the value of the discriminant (b² - 4ac), we can determine the nature of the roots of the quadratic equation. \n",
      "\n",
      "Now go ahead and give me the specific quadratic equation you're working with so we can find its roots.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Avatar definitions\n",
    "avatar_1 = {\"name\": \"Math Genius\", \"model\": \"gpt-3.5-turbo\", \"conversation\": [{\"role\": \"system\", \"content\": \"You are a polite clown who loves joking.\"}]}\n",
    "avatar_2 = {\"name\": \"Physics Expert\", \"model\": \"gpt-4\", \"conversation\": [{\"role\": \"system\", \"content\": \"You are a straightforward physics tutor focused on practical explanations.\"}]}\n",
    "\n",
    "def get_response(avatar):\n",
    "    \"\"\"Generate a response from the model associated with an avatar.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=avatar[\"model\"],\n",
    "            messages=avatar[\"conversation\"],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "def simulate_conversation(turns=10):\n",
    "    \"\"\"Simulate a conversation between two avatars.\"\"\"\n",
    "    for _ in range(turns):\n",
    "        # Avatar 1 responds first\n",
    "        response_1 = get_response(avatar_1)\n",
    "        print(f\"\\n{avatar_1['name']}: {response_1}\")\n",
    "        avatar_1[\"conversation\"].append({\"role\": \"assistant\", \"content\": response_1})\n",
    "        avatar_2[\"conversation\"].append({\"role\": \"user\", \"content\": response_1})\n",
    "\n",
    "        time.sleep(1)  # Pause to simulate conversation flow\n",
    "\n",
    "        # Avatar 2 responds\n",
    "        response_2 = get_response(avatar_2)\n",
    "        print(f\"\\n{avatar_2['name']}: {response_2}\")\n",
    "        avatar_2[\"conversation\"].append({\"role\": \"assistant\", \"content\": response_2})\n",
    "        avatar_1[\"conversation\"].append({\"role\": \"user\", \"content\": response_2})\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "# Run the simulation\n",
    "simulate_conversation(turns=5)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
